{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "' '.join(re.findall('[A-Z][^A-Z]*','WebCuration' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "import folium\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "def clean(file_path):\n",
    "    '''\n",
    "    Parameters\n",
    "        file_path: takes in a file path\n",
    "    Returns\n",
    "        a cleaned df\n",
    "    '''\n",
    "    df = pd.read_csv(file_path,encoding='latin1')\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(['permalink','region','founded_month','founded_quarter'],axis=1,inplace=True)\n",
    "    df['founded_at'] = pd.to_datetime(df['founded_at'],errors='coerce')\n",
    "    df['first_funding_at']= pd.to_datetime(df['first_funding_at'],errors='coerce')\n",
    "    df['last_funding_at']= pd.to_datetime(df['first_funding_at'],errors='coerce')\n",
    "    df['founded_year'] = df['founded_year'].astype('int64')\n",
    "    df.drop(df[df['country_code']=='CAN'].index,inplace=True)\n",
    "    df['funding_total_usd'] = df[' funding_total_usd '].apply(lambda x: x.replace(' ',''))\\\n",
    "        .apply(lambda x: x.replace(',',''))\n",
    "    df['funding_total_usd'] = df['funding_total_usd'].apply(lambda x: x.replace('-','0'))\n",
    "    df['funding_total_usd'] = df['funding_total_usd'].astype('int64')\n",
    "    df['market'] = df[' market '].apply(lambda x: x.replace(' ',''))\n",
    "    df.drop(' market ',axis=1,inplace=True)\n",
    "    df.drop(' funding_total_usd ',axis=1,inplace=True)\n",
    "    df.drop('country_code',axis=1,inplace=True)\n",
    "    df.drop('homepage_url',axis=1,inplace=True)\n",
    "    df.drop('name',axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_engineer(df):\n",
    "    '''\n",
    "    Parameters\n",
    "        df: Takes in a pandas data frame\n",
    "    Returns\n",
    "        a data frame with engineered features\n",
    "    '''\n",
    "    df['time_to_funding'] = abs((df['first_funding_at']-df['founded_at']).dt.days)\n",
    "    test_list = list(df['market'].value_counts().rename_axis('market').reset_index(name='counts')[:20]['market'])\n",
    "    df.loc[~df[\"market\"].isin(test_list), \"market\"] = \"Other\"\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def create_pie_charts(df,column,column_val,target):\n",
    "    '''\n",
    "    Parameters\n",
    "    df: Cleaned data frame\n",
    "    column: column of data frame used to split data as string\n",
    "    column_val: Value we are looking for in column as string\n",
    "    target: The target values we are trying to predict\n",
    "    Returns\n",
    "    a saved image in the images folder\n",
    "    '''\n",
    "    column_val_title = ' '.join(re.findall('[A-Z][^A-Z]*',column_val))\n",
    "    pie_df = df[df[column]==column_val][target].value_counts().rename_axis(target)\\\n",
    "        .reset_index(name='counts')\n",
    "    pie_df['pct'] = pie_df['counts']/len(pie_df)\n",
    "    labels=pie_df[target]\n",
    "    fig, ax = plt.subplots(figsize=(14,7))\n",
    "    ax.pie(pie_df['pct'], explode=[0,0,.15], labels=labels, \\\n",
    "        autopct='%1.1f%%',shadow=True, startangle=50)\n",
    "    ax.axis('equal')\n",
    "    ax.set_title(f'{target.capitalize()} Of {column_val_title} Market')\n",
    "    plt.savefig(f'../images/{column_val}_pie.png',dpi=500)\n",
    "\n",
    "\n",
    "intial_df =clean('../../../Downloads/investments_VC.csv')\n",
    "clean_feat_df=feature_engineer(intial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category_list', 'status', 'state_code', 'city', 'funding_rounds',\n",
       "       'founded_at', 'founded_year', 'first_funding_at', 'last_funding_at',\n",
       "       'seed', 'venture', 'equity_crowdfunding', 'undisclosed',\n",
       "       'convertible_note', 'debt_financing', 'angel', 'grant',\n",
       "       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n",
       "       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n",
       "       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H',\n",
       "       'funding_total_usd', 'market', 'time_to_funding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_feat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_type_df = clean_feat_df.loc[:,'seed':'product_crowdfunding'].apply(lambda x: x>0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_feat_df['status'] = clean_feat_df['status'].apply(lambda x: x.replace('operating','0')).apply(lambda x: x.replace('acquired','1')).apply(lambda x: x.replace('closed','0'))\n",
    "clean_feat_df['status'] = clean_feat_df['status'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8629217791411042\n",
      "Precision: 0.10909090909090909\n",
      "Recall: 0.04419889502762431\n"
     ]
    }
   ],
   "source": [
    "col_list = list(clean_feat_df['market'].value_counts().sort_values().rename_axis('market').reset_index(name='counts')['market'])\n",
    "market_dummies = pd.get_dummies(clean_feat_df['market']).reindex(columns=col_list)\n",
    "state_dummies = pd.get_dummies(clean_feat_df['state_code'])\n",
    "\n",
    "\n",
    "X =market_dummies.iloc[:,:20].join(clean_feat_df['time_to_funding']).values\n",
    "y=clean_feat_df['status'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "y_true = y_test\n",
    "print('Accuracy:', accuracy_score(y_true, y_predict))\n",
    "print(\"Precision:\", precision_score(y_test, y_predict))\n",
    "print(\"Recall:\", recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.85295245398773\n",
      "Out of Bag Score: 0.9175511076287485\n",
      "Precision: 0.165374677002584\n",
      "Recall: 0.12598425196850394\n"
     ]
    }
   ],
   "source": [
    "X =market_dummies.iloc[:,:20].join(state_dummies.iloc[:,:50]).join(clean_feat_df['time_to_funding']).join(funding_type_df).values\n",
    "y=clean_feat_df['status'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True,max_features='sqrt', n_estimators= 50)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score:\", rf.score(X_test, y_test))\n",
    "print(\"Out of Bag Score:\", rf.oob_score_)\n",
    "print(\"Precision:\", precision_score(y_test, y_predict))\n",
    "print(\"Recall:\", recall_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [50,100,150,200,250, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =market_dummies.iloc[:,:20].join(clean_feat_df['time_to_funding']).values\n",
    "y=clean_feat_df['status'].values\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "regr = AdaBoostRegressor(n_estimators=100)\n",
    "regr.fit(X_train,y_train)\n",
    "y_predict = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dummies = pd.get_dummies(clean_feat_df['state_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dummies.iloc[:,:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(25, 51, 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = df['time_to_funding'].values\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "# summarize class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# # summarize the new class distribution\n",
    "# counter = Counter(y)\n",
    "# print(counter)\n",
    "# # scatter plot of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
